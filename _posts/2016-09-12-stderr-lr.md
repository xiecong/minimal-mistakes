---
layout: single
title: "Pseudo R square, standard error and Z-value of logistic regression"
description: "test"
comments: true
---

I was using Weka for logistic regression of categorical dataset. However, weka does not provide statistics output such as R square, z-value of coefficients. So I implemented them and list some of them here.
The logistic function can be written as: $Y = p(1|x_1,x_2, ...,x_p) = \frac{1}{1+e^{-(\beta_0+\beta X)}}$, where $p$ is the number of independent variables.

### Pseudo R square

#### Log likelihood function

The log likehood function of logistic regression is 
$log(L) = \sum_{i}^{n} (1 - y^{(i)}) log(1 - p(1|x_1^{(i)},x_2^{(i)}, ...,x_p^{(i)}))+y^{(i)} log(p(1|x_1^{(i)},x_2^{(i)}, ...,x_p^{(i)}))$, where $n$ is number of the instances.

#### McFadden's Pseudo R square
The McFadden's Pseudo R square is calculated as:
$R^2 = 1 - \frac{log(L_{full})}{log(L_intercept)}$

### Z-value and $P>|z|$ of coefficients

#### Covariance matrix of coeffieicnts

The standard errors of the model coefficients are the square roots of the diagonal entries of the covariance matrix. Consider the following:

Design matrix:

$
X = \begin{bmatrix} 
1 & x_{1,1} & ... & x_{1,p} \\\
1 & x_{2,1} & ... & x_{2,p} \\\
... & ... & ... & ... \\\
1 & x_{n,1} & ... & x_{n,p}
\end{bmatrix} 
$

, where $x_{i,j}$, $x_{i,j}$ is the value of the $j$th predictor for the $i$th observations.
(NOTE: This assumes a model with an intercept.)

$
V = \begin{bmatrix}
\hat{\pi_1}(1-\hat{\pi_1}) & 0 & 0 & 0\\\
0 & \hat{\pi_2}(1-\hat{\pi_2}) & 0 & 0\\\
... & ... & ... & ...\\\
0 & 0 & 0 & \hat{\pi_n}(1-\hat{\pi_n}) 
\end{bmatrix}
$

, where $\hat{\pi_i}$ represents the predicted probability of class membership for observation $i$.
The covariance matrix can be written as:

$$(X^TVX)^{−1}$$


#### Standard error of coefficients
The standard errors are the square root of the diagonal of that matrix. These are the standard errors associated with the coefficients.  The standard error is used for testing whether the parameter is significantly different from 0. The standard errors can also be used to form a confidence interval for the efficient.


#### Z-value
By dividing the coefficient by the standard error you obtain a z-value.

In statistics, the letter “Z” is often used to refer to a random variable that has a standard normal distribution. A standard normal distribution is a normal distribution with expectation 0 and standard deviation 1. This is the normal distribution that is generally tabulated in the back of any basic statistics book.

Because of this, the term “z-value” is often used to refer to the value of a statistic that has a standard normal distribution. Sometimes it is also used to refer to percentile points from the standard normal distribution that are used to compare to the value of statistic. For example, one might refer to “the z-value corresponding to a 95% confidence interval” (which would be 1.96).

#### $P>|z|$
A good rule of thumb is to use a cut-off value of 2 which approximately corresponds to a two-sided hypothesis test with a significance level of $\alpha=0.05$. 
Coefficients having a p-value of 0.05 or less would be statistically significant (i.e., you can reject the null hypothesis and say that the coefficient is significantly different from 0). 
If the z-value is too big in magnitude (i.e., either too positive or too negative), it indicates that the corresponding true regression coefficient is not 0 and the corresponding X-variable matters.

### References

http://www.ats.ucla.edu/stat/stata/output/stata_logistic.htm

http://logisticregressionanalysis.com/1577-what-are-z-values-in-logistic-regression/#Example

http://stats.stackexchange.com/questions/89484/how-to-compute-the-standard-errors-of-a-logistic-regressions-coefficients
