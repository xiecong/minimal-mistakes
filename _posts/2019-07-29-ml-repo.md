---
layout: single
title: "My Minimal Implementation of Commonly-used Machine Learning Algorithms using Only Numpy"
description: "My Github repo of machine learning implementation with only numpy"
comments: true
---
# Simple-Implementation-of-ML-Algorithms
I implementated most common ML algorithms from scratch. Here is the repo: https://github.com/xiecong/Simple-Implementation-of-ML-Algorithms
- For an easy understanding, most of the codes implements only minimal versin of the algorithm.
- The implementation uses only numpy.
- Most algorithms are within 100 lines of codes.

Also see decision boundary visualization for implemented classifiers in decision_boundary_vis.py
![supervised_model](https://raw.githubusercontent.com/xiecong/Simple-Implementation-of-ML-Algorithms/master/supervised_model.png)

Implemented algorithms:

* Regression Models
    * Ridge Regression
        * Matrix solver
        * SGD/Adam solver
    * Logistic Regression
        * Multi-class prediction
    * Factorization Machines
        * Regularization
        * Classification/regression

* Bayes Models
    * Naive Bayes
        * Multinomial model
        * Document tokenizer
    * Beyasian Network
        * Conditional probability MLE
        * Beyasian inference

* Tree Models and Ensemble Learning
    * Decision Tree
        * Classification/regression
        * Different metrics
        * Feature importances
        * Sample weights
    * Random Forest
    * Adaboost
    * Gradient Boost Decision Tree
        * Shrinkage
        * Line search of multiplier
    * XGBoost
        * XGBoost Regression Tree
        * Shrinkage

* Deep Learning Architecture
    * Multilayer Perceptron
    * Convolutional Neural Network
        * Fast layers and vectorized operations
        * WIP: drop out, batch normalization

* Deep Learning Techniques
    * Mini Batch
    * Activation function
        * ReLU
        * Tanh
        * Sigmoid
    * Loss functions
        * Squared error
        * Cross entropy
    * Regularization
        * L1
        * L2

* Optimization Algorithms (See implementations in MLP or Regression)
	* Stochastic Gradient Descent
	* Gradient Descent with Momentum
	* Nesterov Momentum
	* AdaGrad
	* RMSProp
	* Adam

* k-Nearest Neighbors

* Support Vector Machine
    * Soft boundary
    * SMO algorithm
    * Different heuristics for selecting pairs in SMO

* Genetic Algorithm
    * Training a NN model
    * Selection by Fitness
    * Crossover approaches
    * Mutation rate

* Hidden Markov Model
    * Fitting by Baum-Welch
    * Prediction by Viterbi

Work in progress:
* Deep Belief Network
* Recurrent neural network
* Long short-term memory
* Generative Adversarial Networks
* Deep Q-Network (Reinforcement learning)

Feel free to use the code. Please contact me if you have any question :)
